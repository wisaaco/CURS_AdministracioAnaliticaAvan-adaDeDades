{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ff8cc66",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.png)](https://colab.research.google.com/github/wisaaco/CURS_AdministracioAnaliticaAvancadaDeDades/blob/main/lessons/7_algorismes_supervistats_neuronals.ipynb)\n",
    "\n",
    "Si no funciona el botó podeu copiar el següent [enllaç](https://colab.research.google.com/github/wisaaco/CURS_AdministracioAnaliticaAvancadaDeDades/blob/main/lessons/7_algorismes_supervistats_neuronals.ipynb)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac594b299c3bc233",
   "metadata": {},
   "source": [
    "# Unitat 7. Aprenentatge Profund\n",
    "\n",
    "Contingut de la unitat:\n",
    "\n",
    "- Perceptró multicapa\n",
    "- Pytorch\n",
    "- Una xarxa neural\n",
    "- Activitat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd0b9a3004e35ca",
   "metadata": {},
   "source": [
    "## Perceptró multicapa\n",
    "\n",
    "Un Perceptró Multicapa (Multi-Layer Perceptron, _MLP_) és un tipus de xarxa neuronal artificial que funciona de manera similar als mètodes supervisats com SVM (Support Vector Machine) o Random Forest (RF), però amb una estructura més flexible i potent. L’MLP està format per capes de neurones artificials, on cada capa està connectada a la següent. Les dades entren per la primera capa (capa d'entrada), es processen a través d’una o més capes ocultes, i finalment la xarxa dona un resultat a la capa de sortida. A diferència d'altres algorismes d'aprenentatge automàtic que depenen de la creació manual de característiques o regles, l’MLP és capaç d’aprendre relacions complexes entre les dades de manera automàtica ajustant els pesos de les connexions durant el procés d'entrenament, amb un mètode conegut com a retropropagació o propagació cap enrere. \n",
    "\n",
    " Com hem comentat, estan formades per capes de neurones organitzades de manera seqüencial. Aquestes capes estan estructurades en tres components principals:\n",
    "\n",
    "1. **Capa d'entrada**:\n",
    "\n",
    "    - És la capa inicial que rep les dades d'entrada (per exemple, imatges, textos, o valors numèrics).\n",
    "    - El nombre de neurones en aquesta capa és igual al nombre de característiques o atributs de les dades d'entrada.\n",
    "\n",
    "2. **Capes ocultes**:\n",
    "\n",
    "    - Les capes ocultes són les intermèdies entre l'entrada i la sortida.\n",
    "    - Cada neurona d'una capa oculta està connectada a totes les neurones de la capa anterior i a la següent. Aquest tipus de connexió s'anomena totalment connectada o _fully connected_.\n",
    "    - Les neurones d'aquestes capes transformen les dades mitjançant una funció d'activació (per exemple, ReLU, sigmoid, tanh) per capturar relacions no lineals entre les dades.\n",
    "    - Un MLP pot tenir una o més capes ocultes, i el nombre de neurones per capa pot variar. Considerem un MLP com una xarxa profunda a partir de 3 capes ocultes.\n",
    "\n",
    "3. **Capa de sortida**:\n",
    "\n",
    "    - La capa final dona els resultats desitjats del model.\n",
    "    - El nombre de neurones a la capa de sortida depèn del tipus de tasca:\n",
    "        - Per tasques de classificació, hi haurà una neurona per a cada classe.\n",
    "        - Per tasques de regressió, hi haurà una sola neurona que representi el valor de sortida.\n",
    "        - Podem tenir altres mides en la capa de sortida en configuracions de xarxes més avançades.\n",
    "\n",
    "### Propietats clau:\n",
    "\n",
    "   - Pesos i bias: Cada connexió entre neurones té un pes associat, i les neurones tenen un bias. Aquests paràmetres s'actualitzen durant l'entrenament per aprendre a realitzar la tasca.\n",
    "   - Funció de pèrdua: S'utilitza una funció de pèrdua (per exemple, MSE per regressió, cross-entropy per classificació) per mesurar l'error entre la sortida prevista i la sortida real.\n",
    "   - Optimització: Els nous pesos es calculen i s'ajusten mitjançant un algorisme d'optimització com el gradient descendent per minimitzar la funció de pèrdua mitjançant la propagació d'aquests de la darrera capa cap a la primera.\n",
    "\n",
    "\n",
    "A continuació podem observar l'esquema elemental d'aquesta xarxa:\n",
    "\n",
    "![Esquema MLP](images/MultiLayerPerceptron.png \"MLP\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea42cc35f1e8964a",
   "metadata": {},
   "source": [
    "## Pytorch\n",
    "\n",
    "Pytorch és una biblioteca de programari de codi obert dins l'àmbit d'aprenentatge automàtic, està escrita en Python, C++ i CUDA, i basada en la biblioteca del programari Torch del llenguatge LUA. PyTorch va ser desenvolupada inicialment pel departament d'intel·ligència artificial de l'empresa Facebook i l'empresa Uber.\n",
    "\n",
    "Algunes de les seves característiques principals són:\n",
    "1. **Tensor computation (similar a NumPy)**: PyTorch proporciona operacions eficients sobre tensors, una estructura de dades similar als arrays de NumPy però amb capacitat per executar càlculs en GPU o CPU.\n",
    " Això permet aprofitar la potència de les GPUs per millorar la velocitat de càlcul, cosa crucial en l'entrenament de models grans de xarxes neuronals.\n",
    "\n",
    "2. **Autograd (Diferenciació automàtica)**: PyTorch té un sistema integrat per a la diferenciació automàtica, anomenat Autograd. Això significa que calcula automàticament el gradient de les operacions sobre tensors, cosa essencial per entrenar models d'aprenentatge profund amb tècniques com el gradient descendent.\n",
    "\n",
    "3. **Estructures dinàmiques de gràfics computacionals**: PyTorch crea gràfics de computació de manera dinàmica, a diferència d'altres frameworks com TensorFlow que utilitzen gràfics estàtics. Això facilita el debugging i la prototipatge ràpid, ja que el gràfic es crea durant la pròpia execució, el que fa que sigui més intuïtiu i flexible per treballar.\n",
    "\n",
    "4. **Integració amb altres biblioteques Python**: PyTorch es pot integrar fàcilment amb altres paquets de Python com NumPy, SciPy i Pandas, facilitant el desenvolupament d'aplicacions complexes. També és compatible amb altres biblioteques d'aprenentatge profund com Torchvision per a la manipulació de dades visuals.\n",
    "\n",
    "5. **Suport per a CUDA i GPUs**: PyTorch fa ús de CUDA per a aprofitar el càlcul en GPUs de manera eficient. Això permet una millora de rendiment considerable durant l'entrenament de models de grans dimensions, ja que les operacions sobre tensors es poden delegar a la GPU fàcilment amb PyTorch.\n",
    "\n",
    "6. **Modularitat i flexibilitat**: La seva arquitectura modular permet construir models complexos amb més flexibilitat i senzillesa. Els usuaris poden personalitzar capes, funcions de pèrdua, optimitzadors, etc., cosa que facilita l'experimentació. També té un ecosistema ric de biblioteques complementàries (com TorchText, TorchVision, TorchAudio) que s'utilitzen per treballar amb dades de text, imatge, i àudio.\n",
    "\n",
    "7. **Models preentrenats i Transfer Learning**: PyTorch ofereix accés a una àmplia gamma de models preentrenats que es poden utilitzar directament o amb ajustaments menors mitjançant el Transfer Learning. Això és molt útil per a tasques com la classificació d'imatges, la detecció d'objectes, etc., sense necessitat d'entrenar el model des de zero.\n",
    "\n",
    "8. **Comunitat activa i recursos abundants**: PyTorch té una comunitat molt activa, amb molts recursos educatius, tutorials i documentació extensa. A més, la comunitat d’investigació en IA sovint fa servir PyTorch, el que significa que hi ha moltes implementacions de papers acadèmics i models d’avantguarda disponibles.\n",
    "\n",
    "9. **API intuïtiva i fàcil d'usar**: PyTorch està dissenyat per ser intuïtiu per a desenvolupadors i investigadors. La seva API és fàcil de comprendre i utilitzar, cosa que facilita tant el prototipatge ràpid com la producció d'aplicacions escalables.\n",
    "\n",
    "\n",
    "Si ens trobem programant en l'entorn de Google Colab aquesta llibreria (com la majoria) ja es troba instal·lada, però si estam treballant en un entorn local, ens l'haurem d'instal·lar. Al següent [enllaç](https://pytorch.org/get-started/locally/) podreu trobar les instruccions per fer-ho.\n",
    "\n",
    "Començarem a conèixer aquesta llibreria mitjançant l'execució d'un exemple molt senzill. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bddd075820e225b",
   "metadata": {},
   "source": [
    "### Una xarxa neural\n",
    "\n",
    "El problema que volem resoldre és la creació d'una xarxa que sigui capaç de realitzar la predicció del valor mitjà de l'habitatge per als districtes de Califòrnia. Aquest tipus de conjunts es coneixen amb el nom d'exemples de joguina, ja que estan preparats per aconseguir bons resultats amb models relativament simples,.\n",
    "\n",
    " Cada observació és un grup de blocs censals. La variable objectiu és el valor mitjà de l'habitatge en 100.000 USD l'any 1990 i hi ha 8 característiques d'entrada, cadascuna que descriu alguna cosa sobre la casa.\n",
    "\n",
    " - MedInc: ingressos mitjans al grup de blocs.\n",
    " - HouseAge: edat mitjana dels blocs.\n",
    " - AveRooms: nombre mitjà d'habitacions per llar.\n",
    " - AveBedrms: nombre mitjà d'habitacions per llar.\n",
    " - Population: nombre de persones que viuen als blocs.\n",
    " - AveOccup: nombre mitjà de membres de la llar.\n",
    " - Latitude: latitud del centroide del grup de blocs.\n",
    " - Longitude: longitud del centroide del grup de blocs.\n",
    "\n",
    "Aquestes dades tenen la particularitat que diverses característiques es troben en una escala molt diferent. Per exemple, el nombre d'habitacions per habitatge acostuma a ser petit, però la població per bloc sol ser gran. A més, la majoria de les característiques haurien de ser positives, però la longitud ha de ser negativa, recordau que som Califòrnia. El maneig d'aquesta diversitat de dades és un repte per a alguns models d'aprenentatge automàtic i l'hem de resoldre."
   ]
  },
  {
   "cell_type": "code",
   "id": "346eaa68c5c2d2e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T08:40:45.991256Z",
     "start_time": "2024-11-11T08:40:42.910995Z"
    }
   },
   "source": [
    "## Importam les llibreries necessaries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "d8b7114896715019",
   "metadata": {},
   "source": [
    "### Definició de la xarxa\n",
    "\n",
    "Com ja sabem per la secció anterior, aquest és un problema de regressió, a diferència dels problemes de classificació, la variable de sortida és un valor continu. En el cas de les xarxes neuronals, normalment s'utilitza l'activació lineal a la capa de sortida (és a dir, sense activació) de manera que el rang de sortida teòricament pot ser des de l'infinit negatiu fins a l'infinit positiu.\n",
    "\n",
    "El mòdul [torch.nn](https://pytorch.org/docs/stable/nn.html) conté els blocs basics per la construcció de les xarxes. Utilitzarem `nn.Sequential` per definir el nostre model com una seqüència de capes. Aquest és un mòdul que conté altres mòduls i els aplica per produir una sortida. El capa lineal `nn.Linear` calcula la sortida de l'entrada mitjançant una funció lineal i opera els tensors interns pel seu pes i biaix. La capa `nn.ReLU`  aplica una activació no lineal als valors d'entrada d'una xarxa neuronal, convertint tots els valors negatius en zero i deixant els positius tal com són. Aquesta operació introdueix no-linearitat, fent possible que la xarxa pugui aprendre relacions complexes entre les dades. \n",
    "\n",
    "A més de la xarxa també definirem els paràmetres de l'entrenament. En aquest cas:\n",
    "\n",
    "- **Funció de pèrdua**: És la funció que volem minimitzar mitjançant l'entrenament, es a dir, l'indicador de com de bé la xarxa està aprenent. En aquest cas emprarem el `MSE (Mean Squared Error)` error quadratic mitjà [wiki](https://ca.wikipedia.org/wiki/Error_quadr%C3%A0tic_mig).\n",
    "- **Rati d'aprenentatge (_Learning Rate_)**: Representa la velocitat o el pas amb el qual un model d'aprenentatge automàtic ajusta els pesos i els paràmetres durant el procés d'entrenament.\n",
    "- **Algorisme d'Optimització**: Tècnica que s'empra per ajustar els pesos i paràmetres d'un model durant el procés d'entrenament. El seu objectiu principal és minimitzar la funció de pèrdua del model. Els optimitzadors determinen com s‟actualitzen els paràmetres del model en funció de l'error calculat (és dependent de la funció de pèrdua elegida). En el nostre exemple emprarem `Adam` ja que és el més popular.\n",
    "\n",
    "Com no tenim coneixents previs, provarem el disseny tradicional d'una xarxa neuronal, és a dir, l'estructura de la piràmide. Una estructura piramidal és aquella en la que el nombre de neurones de cada capa disminueixi a mesura que la xarxa avança cap a la sortida. El nombre de característiques d'entrada és fix, però  definirem un nombre alt de neurones a la primera capa oculta i reduïrem gradualment el seu nombre a les capes posteriors. Com que en aquest conjunt de dades només hem de predir un valor la capa final només hauria de tenir una neurona."
   ]
  },
  {
   "cell_type": "code",
   "id": "af6626eb3b40976f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T08:40:47.026549Z",
     "start_time": "2024-11-11T08:40:46.002771Z"
    }
   },
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(8, 12),  # Tenim 8 característiques\n",
    "    nn.ReLU(), # introduïm l'activació no lineal a la nostra xarxa.\n",
    "    nn.Linear(12, 6), # anam eliminant dimensionalitat a cada capa\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(6, 1) # tenim una única sortida, el valor a predir\n",
    ")\n",
    "\n",
    "\n",
    "loss_fn = nn.MSELoss()  # mean square error\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "4182008fe080adea",
   "metadata": {},
   "source": [
    "### Obtenció de les dades\n",
    "\n",
    "Com és un conjunt ja preparat, el podem obtenir directament de la llibreria `Sci-kit` que ja coneixem. El dividirem en dos subconjunts, seguint les bones pràctiques de l'àrea, un per entrenar i l'altra per avaluar.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "5eaeb9d72f24dfd1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T08:40:47.703771Z",
     "start_time": "2024-11-11T08:40:47.317740Z"
    }
   },
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "# Obtenim les dades\n",
    "data = fetch_california_housing()\n",
    "X, y = data.data, data.target\n",
    " \n",
    "# Les dividim en els dos conjunts que hem mencionat. El d'entrenament té el 70% de les dades\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True)\n",
    " \n",
    "# Convertim les estructures Numpy a tensors compatibles amb Pytorch\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32).reshape(-1, 1)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "9836104fd382a38b",
   "metadata": {},
   "source": [
    "### Entrenament\n",
    "\n",
    "L'entrenament es duu a terme en forma de bucle, el nombre de cops que s'ha de realitzar aquest bucle es realitzarà és un hiperparàmetre que nosaltres haurem de decidir. A cada iteració de l'entrenament la xarxa realitza una predicció sobre les dades d'entrada i després es calcula l'error mitjà de totes les mostres emprant la funció de pèrdua com a referència d'aquesta manera es sap com s'han de modificar els pesos de la xarxa per aconseguir un bon resultat final. Per tal d'aconseguir un equilibri entre el gran cost que suposaria fer una predicció de cada observació de manera individual i la poca importància que tendría cada observació en la mitja de l'error si es fessin totes les prediccions de cop, es sol cercar un camí intermedi que consisteix a dividir el conjunt de dades en grups anomenats _batches_. \n",
    "\n",
    "Al bucle d'entrenament, la llibreria [tqdm](https://tqdm.github.io/) s'utilitza per configurar una barra de progrés i en cada pas, es calcula i informa del MSE en aquella iteració. Podeu veure com ha canviat el MSE configurant el paràmetre `disable=False` de la funció `tqdm`.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "a8e02af2434837c6",
   "metadata": {},
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "import tqdm\n",
    "\n",
    "n_epochs = 100   # nombre d'iteracions del bucle d'entrenament\n",
    "batch_size = 10  # nombre d'elements que té cada batch\n",
    "batch_start = torch.arange(0, len(X_train), batch_size)\n",
    " \n",
    "# Ens servirà per guardar el millor model\n",
    "best_mse = np.inf   # init to infinity\n",
    "best_weights = None\n",
    "history = []\n",
    " \n",
    "for epoch in range(n_epochs):\n",
    "    model.train() # Posam el model en mode entrenament \n",
    "    \n",
    "    with tqdm.tqdm(batch_start, unit=\"batch\", mininterval=0, disable=True) as bar:\n",
    "        bar.set_description(f\"Epoch {epoch}\")\n",
    "        \n",
    "        for start in bar:\n",
    "            # agafam un batch\n",
    "            X_batch = X_train[start:start+batch_size]\n",
    "            y_batch = y_train[start:start+batch_size]\n",
    "            # realitzem la predicció (passa envant)\n",
    "            y_pred = model(X_batch)\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            # realitzem la passa enrere\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            # actualitzem els pesos\n",
    "            optimizer.step()\n",
    "            \n",
    "            bar.set_postfix(mse=float(loss))\n",
    "    # avaluem el model\n",
    "    model.eval()\n",
    "    y_pred = model(X_test)\n",
    "    mse = loss_fn(y_pred, y_test)\n",
    "    mse = float(mse)\n",
    "    history.append(mse)\n",
    "    if mse < best_mse: # si és el millor en realitzem una copia\n",
    "        best_mse = mse\n",
    "        best_weights = copy.deepcopy(model.state_dict())\n",
    " \n",
    "# carregam el millor model\n",
    "model.load_state_dict(best_weights)\n",
    "print(f\"MSE amb el millor model: {best_mse}\")\n",
    "plt.plot(history)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d987e21f65f2cfec",
   "metadata": {},
   "source": [
    "A l'eix horitzontal podem veure les diferents èpoques d'entrenament i a l'eix vertical com l'error de la predicció de la xarxa es redueix, en les primeres èpoques de manera més ràpida i després es comença a estabilitzar. Hi ha un moment en el qual afegir èpoques no millora l'entrenament.\n",
    "\n",
    "## Activitat\n",
    "\n",
    "En primer lloc, posarem tot el codi en una mateixa cel·la, d'aquesta manera ens serà més senzill poder fer canvis sense tenir errors o resultats incoherents.\n",
    "\n",
    "Una de les majors fonts d'error en executar els nostres entrenaments és tornar a entrenar models que ja s'havien entrenat en execucions anteriors. A cada nou entrenament **hem de crear un objecte nou**, si tenim tot el codi en la mateixa cel·la obligarem a redefinir totes les variables i evitarem aquests errors.\n",
    "\n",
    "Un cop tinguem més experiència amb aquesta llibreria podrem organitzar el codi d'altres maneres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67f2871ed39d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "import tqdm\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(8, 6),  # Tenim 8 característiques\n",
    "    nn.ReLU(), # introduïm l'activació no lineal a la nostra xarxa.\n",
    "    ## TODO: Afegir noves capes\n",
    "    nn.Linear(6, 1) # tenim una única sortida, el valor a predir\n",
    ")\n",
    "\n",
    "\n",
    "loss_fn = nn.MSELoss()  # mean square error\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "\n",
    "n_epochs = 100   # nombre d'iteracions del bucle d'entrenament\n",
    "batch_size = 10  # nombre d'elements que té cada batch\n",
    "batch_start = torch.arange(0, len(X_train), batch_size)\n",
    " \n",
    "# Ens servirà per guardar el millor model\n",
    "best_mse = np.inf   # init to infinity\n",
    "best_weights = None\n",
    "history = []\n",
    " \n",
    "for epoch in range(n_epochs):\n",
    "    model.train() # Posam el model en mode entrenament \n",
    "    \n",
    "    with tqdm.tqdm(batch_start, unit=\"batch\", mininterval=0, disable=True) as bar:\n",
    "        bar.set_description(f\"Epoch {epoch}\")\n",
    "        \n",
    "        for start in bar:\n",
    "            # agafam un batch\n",
    "            X_batch = X_train[start:start+batch_size]\n",
    "            y_batch = y_train[start:start+batch_size]\n",
    "            # realitzem la predicció (passa envant)\n",
    "            y_pred = model(X_batch)\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            # realitzem la passa enrere\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            # actualitzem els pesos\n",
    "            optimizer.step()\n",
    "            \n",
    "            bar.set_postfix(mse=float(loss))\n",
    "    # avaluem el model\n",
    "    model.eval()\n",
    "    y_pred = model(X_test)\n",
    "    mse = loss_fn(y_pred, y_test)\n",
    "    mse = float(mse)\n",
    "    history.append(mse)\n",
    "    if mse < best_mse: # si és el millor en realitzem una copia\n",
    "        best_mse = mse\n",
    "        best_weights = copy.deepcopy(model.state_dict())\n",
    " \n",
    "# carregam el millor model\n",
    "model.load_state_dict(best_weights)\n",
    "print(f\"MSE amb el millor model: {best_mse}\")\n",
    "plt.plot(history)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b321f0ced37a8",
   "metadata": {},
   "source": [
    "1. Prova noves configuracions de la xarxa afegint capes ocultes al `model`. Quina és la configuració que dona el menor error? \n",
    "2. En la descripció del conjunt de dades hem dit que la seva particularitat és que les dades estan a diferent escala. Torna a realitzar el procés de càrrega de dades, però abans de transformar-les a tensors, prova de normalitzar-les (pots mirar [aquest tutorial](https://interactivechaos.com/es/manual/tutorial-de-machine-learning/standardscaler)). Després, entrena un nou model i compara els resultats obtinguts.\n",
    "\n",
    "## Solució\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "bedd7e0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T08:44:03.731915Z",
     "start_time": "2024-11-11T08:41:27.764018Z"
    }
   },
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "# Obtenim les dades\n",
    "data = fetch_california_housing()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Les dividim en els dos conjunts que hem mencionat. El d'entrenament té el 70% de les dades\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Convertim les estructures Numpy a tensors compatibles amb Pytorch\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(8, 12),  # Tenim 8 característiques\n",
    "    nn.ReLU(), # introduïm l'activació no lineal a la nostra xarxa.\n",
    "    nn.Linear(12, 6), # anam eliminant dimensionalitat a cada capa\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(6, 3), # anam eliminant dimensionalitat a cada capa\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(3, 1) # tenim una única sortida, el valor a predir\n",
    ")\n",
    "\n",
    "loss_fn = nn.MSELoss()  # mean square error\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "n_epochs = 100   # nombre d'iteracions del bucle d'entrenament\n",
    "batch_size = 10  # nombre d'elements que té cada batch\n",
    "batch_start = torch.arange(0, len(X_train), batch_size)\n",
    "\n",
    "# Ens servirà per guardar el millor model\n",
    "best_mse = np.inf   # init to infinity\n",
    "best_weights = None\n",
    "history = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train() # Posam el model en mode entrenament \n",
    "\n",
    "    for start in batch_start: # \n",
    "        # agafam un batch\n",
    "        X_batch = X_train[start:start+batch_size]\n",
    "        y_batch = y_train[start:start+batch_size]\n",
    "        # realitzem la predicció (passa envant)\n",
    "        y_pred = model(X_batch)\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        # realitzem la passa enrere\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # actualitzem els pesos\n",
    "        with torch.no_grad():\n",
    "            optimizer.step()\n",
    "\n",
    "    # avaluem el model\n",
    "    model.eval()\n",
    "    y_pred = model(X_test)\n",
    "    mse = loss_fn(y_pred, y_test)\n",
    "    mse = float(mse)\n",
    "    history.append(mse)\n",
    "\n",
    "    if mse < best_mse: # si és el millor en realitzem una copia\n",
    "        best_mse = mse\n",
    "        best_weights = copy.deepcopy(model.state_dict())\n",
    "\n",
    "# carregam el millor model\n",
    "model.load_state_dict(best_weights)\n",
    "print(f\"MSE amb el millor model: {best_mse}\")\n",
    "plt.plot(history)\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE amb el millor model: 1.2980420589447021\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "be9fd45d",
   "metadata": {},
   "source": [
    "[![License: CC BY 4.0](https://img.shields.io/badge/License-CC_BY_4.0-lightgrey.svg)](https://creativecommons.org/licenses/by/4.0/) <br/>\n",
    "Authors: [Isaac Lera](https://personal.uib.cat/isaac.lera), [Miquel Miró](https://personal.uib.cat/miquel.miro) and [Biel Moyà](https://personal.uib.cat/gabriel.moya)<br/>\n",
    "Institution: Universitat de les Illes Balears (UIB) <br/>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
